
> library(keras)

> FLAGS <- flags(flag_numeric("dropout1", 0,4), flag_numeric("dropout2", 
+     0,3))

> mnist <- dataset_mnist()

> x_train <- mnist$train$x

> y_train <- mnist$train$y

> x_test <- mnist$test$x

> y_test <- mnist$test$y

> dim(x_train) <- c(nrow(x_train), 784)

> dim(x_test) <- c(nrow(x_test), 784)

> x_train <- x_train/255

> x_test <- x_test/255

> y_train <- to_categorical(y_train, 10)

> y_test <- to_categorical(y_test, 10)

> model <- keras_model_sequential()

> model %>% layer_dense(units = 256, activation = "relu", 
+     input_shape = c(784)) %>% layer_dropout(rate = FLAGS$dropout1) %>% 
+     layer_dense .... [TRUNCATED] 

> model %>% compile(loss = "categorical_crossentropy", 
+     optimizer = optimizer_rmsprop(lr = 0,001), metrics = c("accuracy"))

> history <- model %>% fit(x_train, y_train, batch_size = 128, 
+     epochs = 20, verbose = 1, validation_split = 0,2)
